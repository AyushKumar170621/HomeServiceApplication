{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeeaa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "#Sentiment Analysis\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download the VADER lexicon for sentiment analysis\n",
    "# nltk.downloader.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d29eba4",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\kvbhk/nltk_data'\n    - 'C:\\\\Users\\\\kvbhk\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kvbhk\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\kvbhk\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kvbhk\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 34\u001b[0m\n\u001b[0;32m     27\u001b[0m reviews \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI love this product! It\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms amazing.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe quality is not as expected. Very disappointed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFast shipping and great customer service.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     31\u001b[0m ]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m reviews:\n\u001b[1;32m---> 34\u001b[0m     sentiment \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreview\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreview\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentiment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentiment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m, in \u001b[0;36manalyze_sentiment\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_sentiment\u001b[39m(review):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Create a SentimentIntensityAnalyzer object\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     sia \u001b[38;5;241m=\u001b[39m \u001b[43mSentimentIntensityAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Get the sentiment scores for the review\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     sentiment_scores \u001b[38;5;241m=\u001b[39m sia\u001b[38;5;241m.\u001b[39mpolarity_scores(review)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\sentiment\\vader.py:340\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.__init__\u001b[1;34m(self, lexicon_file)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    338\u001b[0m     lexicon_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    339\u001b[0m ):\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexicon_file \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexicon_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexicon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_lex_dict()\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstants \u001b[38;5;241m=\u001b[39m VaderConstants()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:750\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m \u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\kvbhk/nltk_data'\n    - 'C:\\\\Users\\\\kvbhk\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kvbhk\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\kvbhk\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kvbhk\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Sentiment Analysis\n",
    "\n",
    "# import nltk\n",
    "# from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# # Download the VADER lexicon for sentiment analysis\n",
    "# nltk.download('vader_lexicon')\n",
    "\n",
    "def analyze_sentiment(review):\n",
    "    # Create a SentimentIntensityAnalyzer object\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Get the sentiment scores for the review\n",
    "    sentiment_scores = sia.polarity_scores(review)\n",
    "\n",
    "    # Classify the sentiment based on the compound score\n",
    "    if sentiment_scores['compound'] >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif sentiment_scores['compound'] <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "reviews = [\n",
    "    \"I love this product! It's amazing.\",\n",
    "    \"The quality is not as expected. Very disappointed.\",\n",
    "    \"Fast shipping and great customer service.\",\n",
    "]\n",
    "\n",
    "for review in reviews:\n",
    "    sentiment = analyze_sentiment(review)\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Sentiment: {sentiment}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea741998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I love this service! It's amazing.\n",
      "Sentiment: Positive\n",
      "\n",
      "Review: The experience was terrible. I won't use it again.\n",
      "Sentiment: Negative\n",
      "\n",
      "Review: It was okay, nothing special.\n",
      "Sentiment: Positive\n",
      "\n",
      "Review: This is the best service ever!\n",
      "Sentiment: Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def analyze_sentiment(review):\n",
    "    analysis = TextBlob(review)\n",
    "\n",
    "    # Classify the sentiment as positive, negative, or neutral\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif analysis.sentiment.polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample reviews\n",
    "    reviews = [\n",
    "        \"I love this service! It's amazing.\",\n",
    "        \"The experience was terrible. I won't use it again.\",\n",
    "        \"It was okay, nothing special.\",\n",
    "        \"This is the best service ever!\",\n",
    "    ]\n",
    "\n",
    "    # Analyze and print sentiment for each review\n",
    "    for review in reviews:\n",
    "        sentiment = analyze_sentiment(review)\n",
    "        print(f\"Review: {review}\\nSentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5130ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ddd7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('home_service_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d30d298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Service ID</th>\n",
       "      <th>Service Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User_1973</td>\n",
       "      <td>Service_5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Good job overall.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User_873</td>\n",
       "      <td>Service_5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Not happy with the service.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User_964</td>\n",
       "      <td>Service_7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>\"Not happy with the service.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User_1263</td>\n",
       "      <td>Service_1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Not happy with the service.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User_1632</td>\n",
       "      <td>Service_18</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Could be better.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>User_1913</td>\n",
       "      <td>Service_12</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>\"Good job overall.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>User_1826</td>\n",
       "      <td>Service_3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Good job overall.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>User_1882</td>\n",
       "      <td>Service_1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>\"Satisfactory work.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>User_1123</td>\n",
       "      <td>Service_12</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>\"Not happy with the service.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>User_1156</td>\n",
       "      <td>Service_10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Not happy with the service.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User ID  Service ID  Service Type  Rating  \\\n",
       "0     User_1973   Service_5             5       4   \n",
       "1      User_873   Service_5             5       2   \n",
       "2      User_964   Service_7             7       3   \n",
       "3     User_1263   Service_1             1       4   \n",
       "4     User_1632  Service_18            18       1   \n",
       "...         ...         ...           ...     ...   \n",
       "4995  User_1913  Service_12            12       3   \n",
       "4996  User_1826   Service_3             3       1   \n",
       "4997  User_1882   Service_1             1       3   \n",
       "4998  User_1123  Service_12            12       5   \n",
       "4999  User_1156  Service_10            10       4   \n",
       "\n",
       "                             Review  \n",
       "0               \"Good job overall.\"  \n",
       "1     \"Not happy with the service.\"  \n",
       "2     \"Not happy with the service.\"  \n",
       "3     \"Not happy with the service.\"  \n",
       "4                \"Could be better.\"  \n",
       "...                             ...  \n",
       "4995            \"Good job overall.\"  \n",
       "4996            \"Good job overall.\"  \n",
       "4997           \"Satisfactory work.\"  \n",
       "4998  \"Not happy with the service.\"  \n",
       "4999  \"Not happy with the service.\"  \n",
       "\n",
       "[5000 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5ba795f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d516f54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of         User ID  Service ID  Service Type  Rating  \\\n",
       "0     User_1973   Service_5             5       4   \n",
       "1      User_873   Service_5             5       2   \n",
       "2      User_964   Service_7             7       3   \n",
       "3     User_1263   Service_1             1       4   \n",
       "4     User_1632  Service_18            18       1   \n",
       "...         ...         ...           ...     ...   \n",
       "4995  User_1913  Service_12            12       3   \n",
       "4996  User_1826   Service_3             3       1   \n",
       "4997  User_1882   Service_1             1       3   \n",
       "4998  User_1123  Service_12            12       5   \n",
       "4999  User_1156  Service_10            10       4   \n",
       "\n",
       "                             Review  \n",
       "0               \"Good job overall.\"  \n",
       "1     \"Not happy with the service.\"  \n",
       "2     \"Not happy with the service.\"  \n",
       "3     \"Not happy with the service.\"  \n",
       "4                \"Could be better.\"  \n",
       "...                             ...  \n",
       "4995            \"Good job overall.\"  \n",
       "4996            \"Good job overall.\"  \n",
       "4997           \"Satisfactory work.\"  \n",
       "4998  \"Not happy with the service.\"  \n",
       "4999  \"Not happy with the service.\"  \n",
       "\n",
       "[5000 rows x 5 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3853c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = data['Service Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d53df79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = set(st)\n",
    "len(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e2ed200",
   "metadata": {},
   "outputs": [],
   "source": [
    "us = data['User ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cc367eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1853"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usl = set(us)\n",
    "len(usl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37579739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
